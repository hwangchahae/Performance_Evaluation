# 학습 전(Pre-Training) 모델 성능 평가 종합 요약

## 평가 개요
- **평가 일시**: 2025년 8월 11일
- **평가 대상**: Qwen 모델 (1.7B, 4B, 8B)
- **평가 상태**: 학습 전 베이스 모델
- **전체 파일 수**: 368개
- **샘플링 크기**: 100개 (27.2%)
- **랜덤 시드**: 42

## 모델별 성능 비교

| 모델 크기 | TF-IDF 코사인 유사도 | Embedding 코사인 유사도 |
|----------|---------------------|------------------------|
| **1.7B** | 0.1878             | 0.9002                |
| **4B**   | 0.2086             | 0.9115                |
| **8B**   | 0.2108             | 0.9178                |

## 주요 발견사항

### 1. TF-IDF 유사도 분석
- **1.7B → 4B**: 11.1% 향상 (0.1878 → 0.2086)
- **4B → 8B**: 1.1% 향상 (0.2086 → 0.2108)
- **전체 향상**: 1.7B 대비 8B는 12.3% 향상

### 2. Embedding 유사도 분석
- **1.7B → 4B**: 1.3% 향상 (0.9002 → 0.9115)
- **4B → 8B**: 0.7% 향상 (0.9115 → 0.9178)
- **전체 향상**: 1.7B 대비 8B는 2.0% 향상

## 성능 패턴 분석

### TF-IDF 기반 평가
- 모델 크기가 커질수록 성능 향상
- 1.7B → 4B 구간에서 가장 큰 성능 향상
- 4B → 8B 구간에서는 향상 폭이 감소 (수렴 경향)

### Embedding 기반 평가
- 모든 모델이 0.90 이상의 높은 유사도 기록
- 모델 크기별 성능 차이가 상대적으로 작음
- 이미 높은 수준에서 점진적 개선

## 결론

1. **모델 크기와 성능의 관계**
   - 두 평가 지표 모두에서 모델 크기가 클수록 성능 향상
   - TF-IDF에서 더 큰 성능 향상폭 관찰

2. **비용 대비 효과**
   - 1.7B → 4B: 상당한 성능 향상 (TF-IDF 11.1%, Embedding 1.3%)
   - 4B → 8B: 제한적 성능 향상 (TF-IDF 1.1%, Embedding 0.7%)
   - 4B 모델이 가장 균형 잡힌 선택일 가능성

3. **학습 전 베이스라인**
   - Embedding 유사도가 이미 매우 높은 수준 (>0.90)
   - TF-IDF 유사도는 상대적으로 낮아 개선 여지가 큼
   - 파인튜닝을 통한 추가 성능 향상 기대

## 권장사항

1. **모델 선택**
   - 리소스 제약이 있는 경우: 4B 모델 권장
   - 최고 성능이 필요한 경우: 8B 모델 선택

2. **파인튜닝 방향**
   - TF-IDF 유사도 개선에 중점
   - 도메인 특화 어휘 학습 강화 필요

3. **추가 평가**
   - 파인튜닝 후 성능 비교 필수
   - 실제 업무 활용 시나리오 기반 평가 권장